{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59658364-4cb1-4a4b-93b1-2f5db3f1502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "MAE  : 1.30\n",
      "RMSE : 1.53\n",
      "R²   : 0.03\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Amazon_Unlocked_Mobile.csv\")\n",
    "\n",
    "# Select features and target\n",
    "X = df[['Price', 'Brand Name', 'Review Votes']].copy()\n",
    "\n",
    "y = df['Rating']\n",
    "\n",
    "# Handle missing values\n",
    "X['Price'].fillna(X['Price'].median(), inplace=True)\n",
    "X['Review Votes'].fillna(X['Review Votes'].median(), inplace=True)\n",
    "X['Brand Name'].fillna(X['Brand Name'].mode()[0], inplace=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocessing: One-hot encode categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Brand Name'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"MAE  : {mae:.2f}\")\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R²   : {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39269b8e-483d-4b95-9d30-05d488106633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL PERFORMANCE (Random Forest Regressor)\n",
      "------------------------------------------\n",
      "MAE  : 1.25\n",
      "RMSE : 1.48\n",
      "R²   : 0.09\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 2. LOAD DATASET\n",
    "# ================================\n",
    "\n",
    "df = pd.read_csv(\"Amazon_Unlocked_Mobile.csv\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3. FEATURE SELECTION\n",
    "# ================================\n",
    "\n",
    "features = ['Price', 'Brand Name', 'Review Votes']\n",
    "target = 'Rating'\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 4. HANDLE MISSING VALUES (SAFE)\n",
    "# ================================\n",
    "\n",
    "X['Price'] = X['Price'].fillna(X['Price'].median())\n",
    "X['Review Votes'] = X['Review Votes'].fillna(X['Review Votes'].median())\n",
    "X['Brand Name'] = X['Brand Name'].fillna(X['Brand Name'].mode()[0])\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 5. TRAIN-TEST SPLIT\n",
    "# ================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 6. PREPROCESSING PIPELINE\n",
    "# ================================\n",
    "\n",
    "categorical_features = ['Brand Name']\n",
    "numerical_features = ['Price', 'Review Votes']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 7. MODEL PIPELINE (BEST FIT)\n",
    "# ================================\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 8. TRAIN MODEL\n",
    "# ================================\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 9. PREDICTIONS\n",
    "# ================================\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 10. MODEL EVALUATION\n",
    "# ================================\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nMODEL PERFORMANCE (Random Forest Regressor)\")\n",
    "print(\"------------------------------------------\")\n",
    "print(f\"MAE  : {mae:.2f}\")\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R²   : {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd67447a-ceee-4cf5-947d-9826bab9bbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLASSIFICATION PERFORMANCE\n",
      "--------------------------\n",
      "Accuracy: 0.6980113087183453\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.09      0.16     25769\n",
      "           1       0.70      0.97      0.82     56999\n",
      "\n",
      "    accuracy                           0.70     82768\n",
      "   macro avg       0.65      0.53      0.49     82768\n",
      "weighted avg       0.67      0.70      0.61     82768\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 2310 23459]\n",
      " [ 1536 55463]]\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 2. LOAD DATA\n",
    "# ================================\n",
    "\n",
    "df = pd.read_csv(\"Amazon_Unlocked_Mobile.csv\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3. CREATE BINARY TARGET\n",
    "# ================================\n",
    "\n",
    "df['Rating_Class'] = np.where(df['Rating'] > 3, 1, 0)\n",
    "\n",
    "X = df[['Price', 'Brand Name', 'Review Votes']].copy()\n",
    "y = df['Rating_Class']\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 4. HANDLE MISSING VALUES\n",
    "# ================================\n",
    "\n",
    "X['Price'] = X['Price'].fillna(X['Price'].median())\n",
    "X['Review Votes'] = X['Review Votes'].fillna(X['Review Votes'].median())\n",
    "X['Brand Name'] = X['Brand Name'].fillna(X['Brand Name'].mode()[0])\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 5. TRAIN-TEST SPLIT\n",
    "# ================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 6. PREPROCESSING\n",
    "# ================================\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Brand Name'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 7. MODEL PIPELINE\n",
    "# ================================\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 8. TRAIN MODEL\n",
    "# ================================\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 9. EVALUATION\n",
    "# ================================\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nCLASSIFICATION PERFORMANCE\")\n",
    "print(\"--------------------------\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "320a1203-93b8-4dd1-8f3f-07c600b4b507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BALANCED CLASSIFICATION PERFORMANCE\n",
      "----------------------------------\n",
      "Accuracy: 0.6030591532959598\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.64      0.50     25769\n",
      "           1       0.78      0.58      0.67     56999\n",
      "\n",
      "    accuracy                           0.60     82768\n",
      "   macro avg       0.60      0.61      0.59     82768\n",
      "weighted avg       0.67      0.60      0.62     82768\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[16621  9148]\n",
      " [23706 33293]]\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# IMPROVED BALANCED CLASSIFIER\n",
    "# ================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=3,\n",
    "        class_weight='balanced',   # ⭐ KEY FIX\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nBALANCED CLASSIFICATION PERFORMANCE\")\n",
    "print(\"----------------------------------\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da4d379-c8cb-4787-bedb-d8bec29b2f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Shape: (891, 15)\n",
      "\n",
      "Dataset Columns:\n",
      " Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "\n",
      "Model Evaluation Results\n",
      "------------------------------\n",
      "Accuracy Score: 0.7933\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83       105\n",
      "           1       0.76      0.73      0.74        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.79      0.78      0.79       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "\n",
      "Model training and evaluation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "============================================================\n",
    "Data Science Internship - Task 1\n",
    "Title : Titanic Survival Prediction\n",
    "Author: Eliya Abbas Sayyed\n",
    "Objective:\n",
    "    Build a simple predictive model using Scikit-learn\n",
    "    to predict passenger survival based on input features.\n",
    "============================================================\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Import Required Libraries\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. Load Dataset\n",
    "# -----------------------------------------------------------\n",
    "# Using Titanic dataset directly from seaborn\n",
    "# This avoids manual downloads and ensures reproducibility\n",
    "\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "\n",
    "# Display basic dataset info (optional for notebook)\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Columns:\\n\", df.columns)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. Select Features and Target Variable\n",
    "# -----------------------------------------------------------\n",
    "# Target:\n",
    "#   survived -> 0 (No), 1 (Yes)\n",
    "# Features selected include both numerical and categorical\n",
    "# to demonstrate preprocessing techniques\n",
    "\n",
    "X = df[['pclass', 'sex', 'age', 'fare', 'embarked']]\n",
    "y = df['survived']\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4. Identify Feature Types\n",
    "# -----------------------------------------------------------\n",
    "# Numerical and categorical features are processed differently\n",
    "\n",
    "numeric_features = ['age', 'fare']\n",
    "categorical_features = ['sex', 'embarked', 'pclass']\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5. Create Preprocessing Pipelines\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Numerical pipeline:\n",
    "# - Fill missing values using median (robust to outliers)\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# Categorical pipeline:\n",
    "# - Fill missing values using most frequent category\n",
    "# - Convert categories into numerical format using One-Hot Encoding\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine both pipelines into a single preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6. Split Data into Training and Testing Sets\n",
    "# -----------------------------------------------------------\n",
    "# 80% training data, 20% testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 7. Build the Machine Learning Pipeline\n",
    "# -----------------------------------------------------------\n",
    "# Pipeline ensures:\n",
    "# - Clean preprocessing\n",
    "# - No data leakage\n",
    "# - Production-ready workflow\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 8. Train the Model\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 9. Make Predictions\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 10. Evaluate Model Performance\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nModel Evaluation Results\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Accuracy Score: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 11. Conclusion\n",
    "# -----------------------------------------------------------\n",
    "# The Logistic Regression model achieves ~78–80% accuracy,\n",
    "# demonstrating strong baseline performance.\n",
    "# The use of pipelines ensures scalability and maintainability.\n",
    "\n",
    "print(\"\\nModel training and evaluation completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418fd85-7647-4232-ac23-8a8d44793f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
